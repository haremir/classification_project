{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be01a8cf",
   "metadata": {},
   "source": [
    "# Model EÄŸitimi ve KarÅŸÄ±laÅŸtÄ±rma\n",
    "\n",
    "Bu notebook, phishing tespit projesi iÃ§in Ã§eÅŸitli makine Ã¶ÄŸrenmesi modellerini eÄŸitir, karÅŸÄ±laÅŸtÄ±rÄ±r ve en iyi modeli seÃ§er.\n",
    "\n",
    "## Ä°Ã§erik:\n",
    "1. **Veri YÃ¼kleme** - Ä°ÅŸlenmiÅŸ train/test verilerini yÃ¼klenecek\n",
    "2. **Model EÄŸitimi** - 4 farklÄ± modeli eÄŸitilecek\n",
    "3. **Model KarÅŸÄ±laÅŸtÄ±rmasÄ±** - Performanslar karÅŸÄ±laÅŸtÄ±rÄ±lacaktÄ±r\n",
    "4. **En Ä°yi Model SeÃ§imi** - En iyi model ve diÄŸer modeller kaydedilecek\n",
    "5. **SonuÃ§lar** - EÄŸitim Ã¶zeti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fd67b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… KÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi!\n",
      "ğŸ“ Proje Dizini: c:\\Users\\PC\\Desktop\\classification_project\n",
      "ğŸ“ Model Dizini: c:\\Users\\PC\\Desktop\\classification_project\\models\n"
     ]
    }
   ],
   "source": [
    "# Gerekli kÃ¼tÃ¼phaneleri import et\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GÃ¶rselleÅŸtirme ayarlarÄ±\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Proje kÃ¶k dizinini Python path'e ekle\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Config ve modÃ¼lleri import et\n",
    "from src import config\n",
    "from src.model_training import (\n",
    "    train_all_models,\n",
    "    compare_models,\n",
    "    save_best_model,\n",
    "    save_all_models,\n",
    "    get_model_summary,\n",
    "    print_model_summary\n",
    ")\n",
    "\n",
    "print(\"âœ… KÃ¼tÃ¼phaneler baÅŸarÄ±yla yÃ¼klendi!\")\n",
    "print(f\"ğŸ“ Proje Dizini: {config.BASE_DIR}\")\n",
    "print(f\"ğŸ“ Model Dizini: {config.MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb0ad7b",
   "metadata": {},
   "source": [
    "## 1. Veri YÃ¼kleme\n",
    "\n",
    "Data Preparation aÅŸamasÄ±nda hazÄ±rlanan train ve test verileri yÃ¼klenecek.\n",
    "\n",
    "**Beklenen Veri:**\n",
    "- Train: 4,679 satÄ±r x 28 sÃ¼tun (27 Ã¶zellik + 1 hedef)\n",
    "- Test: 1,170 satÄ±r x 28 sÃ¼tun (27 Ã¶zellik + 1 hedef)\n",
    "- Ã‡Ä±karÄ±lan Ã¶zellikler: `double_slash_redirecting`, `popUpWidnow`, `port`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "758e872b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VERÄ° YÃœKLEME\n",
      "================================================================================\n",
      "\n",
      "âœ… Veriler baÅŸarÄ±yla yÃ¼klendi!\n",
      "   â€¢ Train: train.csv\n",
      "   â€¢ Test:  test.csv\n",
      "\n",
      "ğŸ“Š Veri BoyutlarÄ±:\n",
      "   â€¢ Train: 4,679 satÄ±r x 28 sÃ¼tun\n",
      "   â€¢ Test:  1,170 satÄ±r x 28 sÃ¼tun\n",
      "   â€¢ Ã–zellik SayÄ±sÄ±: 27\n",
      "\n",
      "ğŸ“‹ SÄ±nÄ±f DaÄŸÄ±lÄ±mlarÄ±:\n",
      "   Train:\n",
      "      â€¢ Phishing (-1): 2,415 (51.61%)\n",
      "      â€¢ Legitimate ( 1): 2,264 (48.39%)\n",
      "   Test:\n",
      "      â€¢ Phishing (-1): 604 (51.62%)\n",
      "      â€¢ Legitimate ( 1): 566 (48.38%)\n",
      "\n",
      "âœ… Veri hazÄ±rlama tamamlandÄ±!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"VERÄ° YÃœKLEME\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Train ve test verilerini yÃ¼kle\n",
    "    train_data = pd.read_csv(config.TRAIN_DATA_FILE)\n",
    "    test_data = pd.read_csv(config.TEST_DATA_FILE)\n",
    "    \n",
    "    print(f\"\\nâœ… Veriler baÅŸarÄ±yla yÃ¼klendi!\")\n",
    "    print(f\"   â€¢ Train: {config.TRAIN_DATA_FILE.name}\")\n",
    "    print(f\"   â€¢ Test:  {config.TEST_DATA_FILE.name}\")\n",
    "    \n",
    "    # Ã–zellik listesini yÃ¼kle\n",
    "    with open(config.PROCESSED_DATA_DIR / \"feature_names.txt\", 'r', encoding='utf-8') as f:\n",
    "        feature_names = [line.strip() for line in f.readlines()]\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Veri BoyutlarÄ±:\")\n",
    "    print(f\"   â€¢ Train: {train_data.shape[0]:,} satÄ±r x {train_data.shape[1]} sÃ¼tun\")\n",
    "    print(f\"   â€¢ Test:  {test_data.shape[0]:,} satÄ±r x {test_data.shape[1]} sÃ¼tun\")\n",
    "    print(f\"   â€¢ Ã–zellik SayÄ±sÄ±: {len(feature_names)}\")\n",
    "    \n",
    "    # Ã–zellik ve hedef deÄŸiÅŸkeni ayÄ±r\n",
    "    X_train = train_data[feature_names]\n",
    "    y_train = train_data[config.TARGET_NAME]\n",
    "    X_test = test_data[feature_names]\n",
    "    y_test = test_data[config.TARGET_NAME]\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ SÄ±nÄ±f DaÄŸÄ±lÄ±mlarÄ±:\")\n",
    "    print(f\"   Train:\")\n",
    "    train_dist = y_train.value_counts().sort_index()\n",
    "    for cls, count in train_dist.items():\n",
    "        label = config.CLASS_LABELS[cls]\n",
    "        percentage = (count / len(y_train)) * 100\n",
    "        print(f\"      â€¢ {label} ({cls:2}): {count:,} ({percentage:.2f}%)\")\n",
    "    \n",
    "    print(f\"   Test:\")\n",
    "    test_dist = y_test.value_counts().sort_index()\n",
    "    for cls, count in test_dist.items():\n",
    "        label = config.CLASS_LABELS[cls]\n",
    "        percentage = (count / len(y_test)) * 100\n",
    "        print(f\"      â€¢ {label} ({cls:2}): {count:,} ({percentage:.2f}%)\")\n",
    "    \n",
    "    print(f\"\\nâœ… Veri hazÄ±rlama tamamlandÄ±!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Hata: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7b477c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TÃœM MODELLERÄ°N EÄÄ°TÄ°MLERÄ°\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "MODEL EÄÄ°TÄ°MÄ° TAMAMLANDI\n",
      "================================================================================\n",
      "âœ… 4 model baÅŸarÄ±yla eÄŸitildi!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TÃœM MODELLERÄ°N EÄÄ°TÄ°MLERÄ°\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# TÃ¼m modelleri eÄŸit\n",
    "all_results = train_all_models(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    config=config,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL EÄÄ°TÄ°MÄ° TAMAMLANDI\")\n",
    "print(\"=\"*80)\n",
    "print(f\"âœ… {len(all_results)} model baÅŸarÄ±yla eÄŸitildi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aa61baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TÃœM MODELLERÄ° KAYDETME\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TÃœM MODELLERÄ° KAYDETME\n",
      "================================================================================\n",
      "âœ… Random Forest             â†’ random_forest.pkl\n",
      "âœ… Decision Tree             â†’ decision_tree.pkl\n",
      "âœ… Gradient Boosting         â†’ gradient_boosting.pkl\n",
      "âœ… Logistic Regression       â†’ logistic_regression.pkl\n",
      "\n",
      "âœ… 4 model baÅŸarÄ±yla kaydedildi!\n",
      "ğŸ“ KayÄ±t Dizini: c:\\Users\\PC\\Desktop\\classification_project\\models\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TÃœM MODELLERÄ° KAYDETME\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# TÃ¼m modelleri kaydet\n",
    "save_all_models(\n",
    "    all_results=all_results,\n",
    "    models_dir=config.MODELS_DIR,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ade282af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AUTOML\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AUTOML BAÅLIYOR (AutoGluon)\n",
      "================================================================================\n",
      "â±ï¸ SÃ¼re: 180 saniye (3.0 dakika)\n",
      "ğŸš€ EÄŸitim baÅŸladÄ±...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tWarning: Exception caused LightGBMXT to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tWarning: Exception caused LightGBM to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tWarning: Exception caused CatBoost to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed. A quick tip is to install via `pip install autogluon.tabular[catboost]==1.4.0`.\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tWarning: Exception caused NeuralNetFastAI to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install autogluon.tabular[fastai]==1.4.0`. \n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tWarning: Exception caused NeuralNetTorch to fail during training (ImportError)... Skipping this model.\n",
      "\t\tUnable to import dependency torch\n",
      "A quick tip is to install via `pip install torch`.\n",
      "The minimum torch version is currently 2.2.\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import lightgbm` failed. A quick tip is to install via `pip install autogluon.tabular[lightgbm]==1.4.0`.\n",
      "\tFailed to import torch or check CUDA availability!Please ensure you have the correct version of PyTorch installed by running `pip install -U torch`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Bitti!\n",
      "\n",
      "ğŸ“Š SonuÃ§lar:\n",
      "   Accuracy:  0.9496\n",
      "   F1-Score:  0.9477\n",
      "   ROC-AUC:   0.9912\n",
      "\n",
      "ğŸ’¾ Model kaydedildi: AutogluonModels/\n",
      "   En iyi: WeightedEnsemble_L2\n",
      "\n",
      "================================================================================\n",
      "KARÅILAÅTIRMA\n",
      "================================================================================\n",
      "              Model  F1-Score  Accuracy  ROC-AUC\n",
      "          AutoGluon    0.9477    0.9496   0.9912\n",
      "      Random Forest    0.0000    0.0000   0.0000\n",
      "      Decision Tree    0.0000    0.0000   0.0000\n",
      "  Gradient Boosting    0.0000    0.0000   0.0000\n",
      "Logistic Regression    0.0000    0.0000   0.0000\n",
      "\n",
      "ğŸ† Kazanan: AutoGluon\n",
      "\n",
      "âœ… Tamam, bitti!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AUTOML - EN BASÄ°T HALÄ°\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AUTOML\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "from src.automl import train_automl, save_automl_model, compare_with_traditional_models\n",
    "\n",
    "# AutoML Ã§alÄ±ÅŸtÄ±r (3 dakika)\n",
    "automl_results = train_automl(X_train, y_train, X_test, y_test, time_limit=180)\n",
    "\n",
    "# Kaydet\n",
    "save_automl_model(automl_results, config.MODELS_DIR / \"automl.pkl\")\n",
    "\n",
    "# KarÅŸÄ±laÅŸtÄ±r\n",
    "comparison = compare_with_traditional_models(automl_results, all_results)\n",
    "\n",
    "# CSV kaydet\n",
    "comparison.to_csv(config.REPORTS_DIR / \"automl_comparison.csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ… Tamam, bitti!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
